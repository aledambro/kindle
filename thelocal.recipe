from __future__ import absolute_import, division, print_function, unicode_literals
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.utils.magick import Image
from datetime import datetime, timedelta
yesterday = datetime.now() - timedelta(days=1)

sections = [
    ("The Local", "https://www.thelocal.dk/"),
    
]

# Change this to True if you want grey images
convert_to_grayscale = True

# ----------- CUSTOMIZATION OPTIONS OVER -----------

prefixes = {"Permalink to", "Commenta", "Link all'articolo"}


class IlPost(BasicNewsRecipe):
    __author__ = 'Marco Scirea'
    __license__ = 'GPL v3'
    __copyright__ = '2019, Marco Scirea <marco.prolog at gmail.com>'

    title = "The Local"
    language = "en"
    description = (
        'Puoi decidere quali sezioni scaricare modificando la ricetta.'
        ' Di default le immagini sono convertite in scala di grigio per risparmiare spazio,'
        ' la ricetta puo\' essere configurata per tenerle a colori'
    )
    tags = "news"
    cover_url = "https://images.app.goo.gl/osydek1Ujab3draD9"
    ignore_duplicate_articles = {"title", "url"}
    no_stylesheets = True
    keep_only_tags = [dict(id=["expanding", "singleBody"])]

    def parse_page(self, name, url):
        self.log.debug(url)
        soup = self.index_to_soup(url)
        entries = []
        for article in soup.findAll('article'):
            for link in article.findAll('a', href=True, title=True):
                if not link["href"].startswith("https://www.thelocal.dk"+ time.strftime('%Y%m%d')) | link["href"].startswith("https://www.thelocal.dk"+ yesterday.strftime('%Y%m%d')):
                    continue
                title = link["title"]
                for prefix in prefixes:
                    if title.startswith(prefix):
                        title = title.lstrip(prefix)
                        break
                title = title.strip()
                entries.append({
                    "url": link["href"],
                    "title": title,
                })
        return (name, entries)

    def populate_article_metadata(self, article, soup, first):
        description = soup.find(attrs={"name": "description"})
        article.summary = description[
            "content"] if description else "No meta description given"
        article.text_summary = description[
            "content"] if description else "No meta description given"

    def parse_index(self):
        feeds = []
        for section in sections:
            feeds.append(self.parse_page(section[0], section[1]))
        return feeds

    def postprocess_html(self, soup, first):
        if convert_to_grayscale:
            #process all the images
            for tag in soup.findAll(lambda tag: tag.name.lower()=='img' and tag.has_key('src')):
                iurl = tag['src']
                img = Image()
                img.open(iurl)
                if img < 0:
                    raise RuntimeError('Out of memory')
                img.type = "GrayscaleType"
                img.save(iurl)
        return soup
